{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Roll Number : 1\n",
      "Exam Duration -  19221\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random as rng\n",
    "import datetime\n",
    "import dlib\n",
    "import face_recognition as fr\n",
    "import csv\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "roll = input(\"Enter Roll Number : \")\n",
    "\n",
    "\n",
    "def calculate_eye(eye):\n",
    "        A = distance.euclidean(eye[1], eye[5])\n",
    "        B = distance.euclidean(eye[2], eye[4])\n",
    "        C = distance.euclidean(eye[0], eye[3])\n",
    "        eye_aspect_ratio = (A+B)/(2.0*C)\n",
    "        return eye_aspect_ratio\n",
    "\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "dlib_facelandmark = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Initializations\n",
    "center_left = 85\n",
    "center_right = 110\n",
    "\n",
    "start_of_exam = datetime.datetime.now()\n",
    "time_stamp = datetime.datetime.now()\n",
    "next = start_of_exam\n",
    "diff_time = 1500\n",
    "\n",
    "out_of_frame = []\n",
    "motion_stamps = []\n",
    "\n",
    "max_frame_width = 200\n",
    "max_frame_height = 120\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.7\n",
    "\n",
    "\n",
    "####Face Recognition\n",
    "\n",
    "\n",
    "image_directory = 'C:\\\\Users\\\\POWER\\\\Downloads\\\\WSD Lab Term Project\\\\Images Directory\\\\' + str(roll) + '.jpg'\n",
    "person_image = fr.load_image_file(image_directory)\n",
    "\n",
    "#person_image = fr.load_image_file(r'C:\\Users\\POWER\\Downloads\\WSD Lab Term Project\\rishav.jpg')\n",
    "person_face_encoding = fr.face_encodings(person_image)[0]\n",
    "\n",
    "known_face_encodings = [person_face_encoding]\n",
    "known_face_names = [\"Rishav\"]\n",
    "\n",
    "\n",
    "\n",
    "####Smartphone and Multiple Person Detector\n",
    "# Load Yolo\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "classes = []\n",
    "\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if ret is False:\n",
    "        break\n",
    "      \n",
    "    height,width = frame.shape[:2]   \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    ##### Detecting objects\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    \n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.1:\n",
    "                \n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "                \n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    count_of_person = 0\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = colors[i]\n",
    "            if label == 'person':\n",
    "                count_of_person = count_of_person + 1\n",
    "                \n",
    "            if count_of_person > 1:\n",
    "                motion_stamps.append([\"Several People\", round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)])\n",
    "                diff = round((datetime.datetime.now()-next).total_seconds()*1000)\n",
    "                    \n",
    "                if diff > diff_time :\n",
    "                    filename = str(round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)) + \".jpg\"\n",
    "                    cv2.imwrite(filename,frame)\n",
    "                    next = datetime.datetime.now()\n",
    "                cv2.putText(frame,  \n",
    "                        'Several People',  \n",
    "                        (200, 100),  \n",
    "                        font, 1,  \n",
    "                        (0, 255, 255),  \n",
    "                        2,  \n",
    "                        cv2.LINE_4) \n",
    "                \n",
    "            if label == 'cell phone' :\n",
    "                diff = round((datetime.datetime.now()-next).total_seconds()*1000)\n",
    "                    \n",
    "                if diff > diff_time :\n",
    "                    filename = str(round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)) + \".jpg\"\n",
    "                    cv2.imwrite(filename,frame)\n",
    "                    next = datetime.datetime.now()\n",
    "                motion_stamps.append([\"Smartphone\", round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)])\n",
    "                cv2.putText(frame,  \n",
    "                        'Smart Phone',  \n",
    "                        (50, 100),  \n",
    "                        font, 1,  \n",
    "                        (0, 255, 255),  \n",
    "                        2,  \n",
    "                        cv2.LINE_4)\n",
    "     \n",
    "    if count_of_person == 0:\n",
    "        diff = round((datetime.datetime.now()-next).total_seconds()*1000)\n",
    "\n",
    "        if diff > diff_time :\n",
    "            filename = str(round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)) + \".jpg\"\n",
    "            cv2.imwrite(filename,frame)\n",
    "            next = datetime.datetime.now()\n",
    "        motion_stamps.append([\"Person not in frame\", round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)])\n",
    "\n",
    "    \n",
    "        \n",
    "    ##### Face Recognition\n",
    "\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "    face_locations = fr.face_locations(rgb_frame)\n",
    "    face_encodings = fr.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    for (top, right, bottom ,left), face_encoding in zip(face_locations, face_encodings):\n",
    "\n",
    "        matches = fr.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        face_distances = fr.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "\n",
    "        if name == \"Unknown\":\n",
    "            cv2.putText(frame,\"Not recognised\",(200,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,100,0), 2, cv2.LINE_4)\n",
    "            \n",
    "            if count_of_person == 1 :\n",
    "                motion_stamps.append([\"Unknown Person Detected\", round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    ##### Gaze Detector Code - includes eye tracking and head pose detector\n",
    "\n",
    "    for face in faces:\n",
    "\n",
    "        face_landmarks = dlib_facelandmark(gray, face)\n",
    "\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##### Head Pose Estimator\n",
    "        \n",
    "        '''tip of nose/left of eye/right of eye/mouth left/mouth right'''\n",
    "        face_coords = []\n",
    "\n",
    "        for n in range(32,35):\n",
    "                sum_x = sum_x + face_landmarks.part(n).x\n",
    "                sum_y = sum_y + face_landmarks.part(n).y\n",
    "\n",
    "        #Tip of Nose\n",
    "        face_coords.append((int(sum_x/3),int(sum_y/3)))\n",
    "\n",
    "        #Left eye end to tip of nose\n",
    "        face_coords.append((face_landmarks.part(36).x,face_landmarks.part(36).y))\n",
    "        ln = distance.euclidean(face_coords[0],face_coords[1])\n",
    "\n",
    "        #Right eye end to tip of nose\n",
    "        face_coords.append((face_landmarks.part(45).x,face_landmarks.part(45).y))\n",
    "        rn = distance.euclidean(face_coords[0],face_coords[2])\n",
    "\n",
    "        #left mouth end to tip of nose\n",
    "        face_coords.append((face_landmarks.part(48).x,face_landmarks.part(48).y))\n",
    "        lmn = distance.euclidean(face_coords[0],face_coords[3])\n",
    "\n",
    "        #Right mouth end to tip of nose\n",
    "        face_coords.append((face_landmarks.part(54).x,face_landmarks.part(54).y))\n",
    "        rmn = distance.euclidean(face_coords[0],face_coords[4])\n",
    "\n",
    "        gaze_tester = (rn + rmn)/(ln + lmn)\n",
    "        alignment_tester = (rn + ln)/ (rmn + lmn)\n",
    "        \n",
    "        head_down = 0\n",
    "        head_right = 0\n",
    "        head_left = 0\n",
    "\n",
    "        if alignment_tester > 2.2:\n",
    "            cv2.putText(frame, \"Head Down\", (150,350), font, 2, (0, 0, 255), 4)\n",
    "            head_down = 1\n",
    "\n",
    "            if gaze_tester > 1.18:\n",
    "                cv2.putText(frame, \"Head Right\", (50,400), font, 2, (0, 0, 255), 4)\n",
    "                head_right = 1\n",
    "            elif gaze_tester < 0.83:\n",
    "                cv2.putText(frame, \"Head Left\", (50,400), font, 2, (0, 0, 255), 4)\n",
    "                head_left = 1\n",
    "        \n",
    "        else :\n",
    "            if gaze_tester > 1.25:\n",
    "                cv2.putText(frame, \"Head Right\", (50,400), font, 2, (0, 0, 255), 4)\n",
    "                head_right = 1\n",
    "            elif gaze_tester < 0.8:\n",
    "                cv2.putText(frame, \"Head Left\", (50,400), font, 2, (0, 0, 255), 4)\n",
    "                head_left = 1\n",
    "                \n",
    "        head_estimator_ud = head_down\n",
    "        head_estimator_rl = head_right + head_left\n",
    "                \n",
    "                \n",
    "        #### Eye Gaze Estimator\n",
    "        rightEye = []\n",
    "        leftEye = []\n",
    "\n",
    "        for n in range(42,48):\n",
    "                x = face_landmarks.part(n).x\n",
    "                y = face_landmarks.part(n).y\n",
    "                rightEye.append((x,y))\n",
    "                next_point = n+1\n",
    "                if n == 47:\n",
    "                        next_point = 42\n",
    "                if n == 42:\n",
    "                    left_r = x\n",
    "                if n == 45:\n",
    "                    right_r = x\n",
    "                if n == 43:\n",
    "                    up_r = y\n",
    "                if n == 47:\n",
    "                    down_r = y\n",
    "                    \n",
    "        for n in range(36,42):\n",
    "                x = face_landmarks.part(n).x\n",
    "                y = face_landmarks.part(n).y\n",
    "                leftEye.append((x,y))\n",
    "                next_point = n+1\n",
    "                if n == 41:\n",
    "                        next_point = 36\n",
    "                if n == 36:\n",
    "                    left_l = x\n",
    "                if n == 39:\n",
    "                    right_l = x\n",
    "                if n == 37:\n",
    "                    up_l = y\n",
    "                if n == 41:\n",
    "                    down_l = y\n",
    "\n",
    "        right_eye = calculate_eye(rightEye)\n",
    "        left_eye = calculate_eye(leftEye)\n",
    "\n",
    "        EYE = (right_eye+left_eye)/2\n",
    "        EYE = round(EYE,2)\n",
    "\n",
    "        frame_of_eye_r = frame[up_r-2:down_r+2,left_r-2:right_r+2]\n",
    "        roi_r = cv2.resize(frame_of_eye_r, (max_frame_width,max_frame_height))\n",
    "\n",
    "        frame_of_eye_l = frame[up_l-2:down_l+2,left_l-2:right_l+2]\n",
    "        roi_l = cv2.resize(frame_of_eye_l, (max_frame_width,max_frame_height))\n",
    "\n",
    "        if EYE > 0.18 :\n",
    "\n",
    "\n",
    "            # Extracting the height and width of an image \n",
    "            rows, cols = roi_r.shape[:2]\n",
    "\n",
    "            # generating vignette mask using Gaussian \n",
    "            # resultant_kernels\n",
    "            X_resultant_kernel = cv2.getGaussianKernel(cols,200)\n",
    "            Y_resultant_kernel = cv2.getGaussianKernel(rows,200)\n",
    "            \n",
    "\n",
    "            #generating resultant_kernel matrix \n",
    "            resultant_kernel = Y_resultant_kernel * X_resultant_kernel.T\n",
    "\n",
    "            #creating mask and normalising by using np.linalg\n",
    "            # function\n",
    "            mask = 200 * resultant_kernel / np.linalg.norm(resultant_kernel)\n",
    "\n",
    "\n",
    "            # applying the mask to each channel in the input image\n",
    "            for i in range(3):\n",
    "                roi_r[:,:,i] = roi_r[:,:,i] * mask\n",
    "                roi_l[:,:,i] = roi_l[:,:,i] * mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            gray_roi_r = cv2.cvtColor(roi_r, cv2.COLOR_BGR2GRAY)\n",
    "            (minVal_r, maxVal_r, minLoc_r, maxLoc_r) = cv2.minMaxLoc(gray_roi_r)\n",
    "            cv2.circle(roi_r, maxLoc_r, 15, (255, 0, 0), 2)\n",
    "            \n",
    "\n",
    "            gray_roi_l = cv2.cvtColor(roi_l, cv2.COLOR_BGR2GRAY)\n",
    "            (minVal_l, maxVal_l, minLoc_l, maxLoc_l) = cv2.minMaxLoc(gray_roi_l)\n",
    "            cv2.circle(roi_l, maxLoc_l, 15, (255, 0, 0), 2)\n",
    "            \n",
    "            x=maxLoc_r[0]\n",
    "            a=maxLoc_l[0]\n",
    "            y=maxLoc_r[1]\n",
    "            b=maxLoc_l[1]\n",
    "\n",
    "            if (x<center_left and a<center_left) or (x<center_left and a>center_right) or (a<center_left and x>center_right) or (x>center_right and a>center_right):\n",
    "                if head_estimator_rl > 0 :\n",
    "                    motion_stamps.append([\"Either Head or Eye Twisted\",round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)])\n",
    "                    cv2.putText(frame,  \n",
    "                        'Either Head or Eye Twisted ',  \n",
    "                        (50, 50),  \n",
    "                        font, 1,  \n",
    "                        (0, 255, 255),  \n",
    "                        2,  \n",
    "                        cv2.LINE_4)\n",
    "                    diff = round((datetime.datetime.now()-next).total_seconds()*1000)\n",
    "                    \n",
    "                    if diff > diff_time :\n",
    "                        filename = str(round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)) + \".jpg\"\n",
    "                        cv2.imwrite(filename,frame)\n",
    "                        next = datetime.datetime.now()\n",
    "                else :\n",
    "                    \n",
    "                    cv2.putText(frame,  \n",
    "                        'Eyeball at Center',  \n",
    "                        (50, 50),  \n",
    "                        font, 1,  \n",
    "                        (0, 255, 255),  \n",
    "                        2,  \n",
    "                        cv2.LINE_4)\n",
    "\n",
    "\n",
    "            else :\n",
    "                motion_stamps.append([\"Gazing\",round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)])\n",
    "                diff = round((datetime.datetime.now()-next).total_seconds()*1000)\n",
    "                \n",
    "                if diff > diff_time :\n",
    "                    filename = str(round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)) + \".jpg\"\n",
    "                    cv2.imwrite(filename,frame)\n",
    "                    next = datetime.datetime.now()\n",
    "                cv2.putText(frame,  \n",
    "                    'Gazing',  \n",
    "                    (50, 50),  \n",
    "                    font, 1,  \n",
    "                    (0, 255, 255),  \n",
    "                    2,  \n",
    "                    cv2.LINE_4)\n",
    "\n",
    "\n",
    "            cv2.imshow(\"frame\",frame)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            if head_estimator_rl > 0 :\n",
    "                motion_stamps.append([\"Head Twisted and Eye closed for Webcam\",round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)])\n",
    "                cv2.putText(frame,  \n",
    "                    'Head Twisted ',  \n",
    "                    (50, 50),  \n",
    "                    font, 1,  \n",
    "                    (0, 255, 255),  \n",
    "                    2,  \n",
    "                    cv2.LINE_4)\n",
    "                diff = round((datetime.datetime.now()-next).total_seconds()*1000)\n",
    "                \n",
    "                if diff > diff_time :\n",
    "                    filename = str(round((datetime.datetime.now()-start_of_exam).total_seconds()*1000)) + \".jpg\"\n",
    "                    cv2.imwrite(filename,frame)\n",
    "                    next = datetime.datetime.now()\n",
    "                \n",
    "            cv2.putText(frame,  \n",
    "                        'Closed for webCam',  \n",
    "                        (300, 100),  \n",
    "                        font, 1,  \n",
    "                        (0, 255, 255),  \n",
    "                        2,  \n",
    "                        cv2.LINE_4)\n",
    "            cv2.imshow(\"frame\",frame)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'): \n",
    "\n",
    "        end_of_exam = datetime.datetime.now()\n",
    "        exam_duration = round((end_of_exam - start_of_exam).total_seconds()*1000)\n",
    "        \n",
    "        #print(motion_stamps)\n",
    "        print(\"Exam Duration - \",exam_duration)\n",
    "        with open('Gazing_instances.csv', 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(motion_stamps)\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
